{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, normalization, kernel = 3, stride = 2, padding = 1, activation = nn.LeakyReLU(0.2, True), is_bias = False):\n",
    "        super(Discriminator_Conv, self).__init__()\n",
    "\n",
    "        # Now initializing all the all variables\n",
    "        self.channel = channels\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.is_bias = is_bias\n",
    "        # self.normalization = normalization\n",
    "        # self.activation = activation\n",
    "\n",
    "        # now making the conv block\n",
    "\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(self.channel, self.channel, self.kernel, self.stride, self.padding, bias = is_bias),\n",
    "            activation,\n",
    "            nn.Conv2d(self.channel, self.channel*2, self.kernel, 1, padding = 'same', bias = is_bias),\n",
    "            normalization,\n",
    "            activation,\n",
    "        )\n",
    "    \n",
    "    def forward(self,img):\n",
    "        out_img = self.conv_layer(img)\n",
    "        return out_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, args = {'name' : 'discriminator1', 'bias' : False, 'n_blocks' : 7, 'initial_channels' : 32, 'size' : (256,256),} ):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # initializing the parameters\n",
    "        self.name = args['name']\n",
    "        self.bias = args['bias']\n",
    "\n",
    "        # n_blocks\n",
    "        self.n_blocks = args['n_blocks']\n",
    "\n",
    "        # initializing the initial channels\n",
    "        self.initial_channels = args['initial_channels']\n",
    "\n",
    "        # initial size\n",
    "        self.h,self.w = args['size']\n",
    "        h,w = self.h,self.w\n",
    "\n",
    "        # now initializing the initial layer\n",
    "        self.initial_conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, self.initial_channels, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        )\n",
    "\n",
    "        print(f\"Warning : Please Try to give image of size as power to two, in-order to avoid any dimensionality errors\")\n",
    "\n",
    "        intermediate_layers = []\n",
    "        channels = self.initial_channels\n",
    "\n",
    "        # defining the conv blocks\n",
    "        for i in range(self.n_blocks):\n",
    "\n",
    "            # getting the image dim\n",
    "            c,h,w = channels*2,h//2,w//2\n",
    "\n",
    "            # just defining a yet another type of normalization to experiment with\n",
    "            # nn.InstanceNorm2d(c)\n",
    "            # nn.LayerNorm([c,h,w])\n",
    "            # nn.GroupNorm(1,c) # -> equivalent to layer Norm without element-wise affine\n",
    "\n",
    "            # defining the block\n",
    "            block = Discriminator_Conv(channels = channels, normalization = nn.GroupNorm(1,c), kernel = 3, stride = 2, padding = 1, activation = nn.LeakyReLU(0.2, True), is_bias = self.bias)\n",
    "\n",
    "            # appending the block\n",
    "            intermediate_layers.append(block)\n",
    "\n",
    "            # updating the channels\n",
    "            channels = channels*2\n",
    "        \n",
    "        self.intermediate_conv_layer = nn.Sequential(*intermediate_layers)\n",
    "\n",
    "        # getting the channels and image size after coming out of the loop\n",
    "        c,h,w = channels,h,w\n",
    "\n",
    "        # Now making the final conv layer to classify the output\n",
    "        self.out_conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1, bias = self.bias),\n",
    "            nn.GroupNorm(1,c),\n",
    "            nn.LeakyReLU(0.2,True),\n",
    "            nn.Conv2d(channels, 1, 3, 1, 1, bias = True),\n",
    "        )\n",
    "    \n",
    "    # Now we have defined all layers\n",
    "\n",
    "    def forward(self,img):\n",
    "\n",
    "        out_img = self.initial_conv_layer(img)\n",
    "        out_img = self.intermediate_conv_layer(out_img)\n",
    "        out_img = self.out_conv_layer(out_img)\n",
    "\n",
    "        return out_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : Please Try to give image of size as power to two, in-order to avoid any dimensionality errors\n"
     ]
    }
   ],
   "source": [
    "# d_args = {'name' : 'discriminator1', 'bias' : False, 'n_blocks' : 3, 'initial_channels' : 32, 'size' : (256,256),}\n",
    "# d_model = Discriminator(args = d_args,).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (initial_conv_layer): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  )\n",
       "  (intermediate_conv_layer): Sequential(\n",
       "    (0): Discriminator_Conv(\n",
       "      (conv_layer): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Discriminator_Conv(\n",
       "      (conv_layer): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Discriminator_Conv(\n",
       "      (conv_layer): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "        (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out_conv_layer): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the model\n",
    "# d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Learnable weights in the model is : 1.175M\n"
     ]
    }
   ],
   "source": [
    "# # printing total learnable weights in the model \n",
    "# print(f\"Total Learnable weights in the model is : {sum([p.numel() for p in d_model.parameters() if p.requires_grad])*1e-6:.3f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864  -  torch.Size([32, 3, 3, 3])\n",
      "32  -  torch.Size([32])\n",
      "9216  -  torch.Size([32, 32, 3, 3])\n",
      "18432  -  torch.Size([64, 32, 3, 3])\n",
      "64  -  torch.Size([64])\n",
      "64  -  torch.Size([64])\n",
      "36864  -  torch.Size([64, 64, 3, 3])\n",
      "73728  -  torch.Size([128, 64, 3, 3])\n",
      "128  -  torch.Size([128])\n",
      "128  -  torch.Size([128])\n",
      "147456  -  torch.Size([128, 128, 3, 3])\n",
      "294912  -  torch.Size([256, 128, 3, 3])\n",
      "256  -  torch.Size([256])\n",
      "256  -  torch.Size([256])\n",
      "589824  -  torch.Size([256, 256, 3, 3])\n",
      "256  -  torch.Size([256])\n",
      "256  -  torch.Size([256])\n",
      "2304  -  torch.Size([1, 256, 3, 3])\n",
      "1  -  torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# for p in d_model.parameters():\n",
    "#     print(p.numel(),' - ',p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image is : torch.Size([3, 256, 256])\n",
      "Shape of the output image is : torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25347bd7070>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ### Testing the model by passing a image\n",
    "\n",
    "# transformations = transforms.Compose([\n",
    "#     transforms.Resize((256,256)),\n",
    "#     transforms.ToTensor(),\n",
    "#     ])\n",
    "\n",
    "# img = transformations( Image.open('../../All Content Image/animals/b-1.jpg').convert('RGB') )\n",
    "# print(f\"Shape of the image is : {img.shape}\")\n",
    "# out_img = d_model(img.to(device))\n",
    "# print(f\"Shape of the output image is : {out_img.shape}\")\n",
    "\n",
    "# out_img = transforms.ToPILImage()(out_img)\n",
    "# plt.imshow(out_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
